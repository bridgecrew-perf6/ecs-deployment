:table-caption!:
:toc:
= ECS Deployment

== Requirements

To run this deployment all you need is `docker` and `docker-compose` and the correct `DNS` entries.
Please add these records to your domain name (replace `<ip>` & `<domain>` with the ip and domain name of the machine):

[source,txt]
----
@       IN  A   <ip>
@       IN  MX  1  <domain>.
@       IN  TXT "v=spf1 mx ~all"
_dmarc  IN  TXT "v=DMARC1; p=quarantine"
----

Also don't forget to set the reverse lookup. Almost all mail services rejects emails if no PTR record is found.

== First time setup [[first_time_setup]]

Please follow the order of scripts for the first setup. Otherwise the files will be created in the wrong order.
Create a `.env` file:

[source,bash]
----
./scripts/generate-env.sh domain.name
----

This will generate a `.env` file with the following variables:

.Basic Variables
[cols="1,1,1"]
|===
|Variable Name |Example Value |Description

|HOST
|example.com
|This is used for the reverse proxy. With this variable the request is resolved to the correct container with the correct host header. This also make it possible to use `let's encrypt`

|ECS_COMMISSION_UUID
|ecececececececececececececececec
|The `ECS` needs this variable to determine which ethic commission this instance belongs to. See https://ecs-org.github.io/ecs-docs/admin-manual/configuration.html#selecting-the-ethics-commission-uuid[here] for all the `uuids`. Don't forget to set this variable

|ECS_USERSWITCHER_ENABLED
|false
|whether the user switch is enable or disabled (This should only be `true` in a staging environment)
|===

.Hardcoded Production Variables
[cols="1,1,1"]
|===
|Variable Name |Value |Description

|ECS_PROD
|true
|`Django` sets all the necessary settings for a production environment when `ECS_PROD` is true.

|ECS_DOMAIN
|${HOST}
|Resolves to the `HOST` variable. `Django` needs a `DOMAIN` variable for the `ALLOWED_HOSTS`.

|DATABASE_URL
|postgres://ecs:ecs@database:5432/ecs
|Postgres URI for connecting to the `database` container

|REDIS_URL
|redis://redis:6379/0
|Redis URI for connecting to the `redis` container

|MEMCACHED_URL
|memcached://memcached:11211
|Memcached URI for connecting to the `memcached` container

|SMTP_URL
|smtp://mailserver:25
|Smtp URI for connecting to the `mailserver` container

|===

.Generated Variables
[cols="1,1"]
|===
|Variable Name |Description

|ECS_SECRET_KEY
|`Django` specific secret key

|ECS_REGISTRATION_SECRET
|`Django` specific secret key

|ECS_PASSWORD_RESET_SECRET
|`Django` specific secret key

|ECS_VAULT_ENCRYPT
|Used for encrypting and decrypting files in the `storage-vault`

|ECS_VAULT_SIGN
|Used for encrypting and decrypting files in the `storage-vault`

|===

=== Docker network

We need to create a docker network for the deployment:

[source,bash]
----
sudo docker network create ecs-reverse-proxy
----

=== Postgres database

Start the database:

[source,bash]
----
sudo docker-compose up -d database
----

The database is empty. We will need to fill it with migrations:

[source,bash]
----
sudo docker-compose run --rm ecs.web migrate
----

=== Traefik reverse proxy

No container is connected to the outside world. With the reverse proxy all the needed containers can be exposed:

[source,bash]
----
sudo docker-compose up -d reverse-proxy
----

But traefik won't request a certifcate from letencrypt unless it is needed. So we will start a dummy server:

[source,bash]
----
sudo docker-compose -f dummy-webserver-compose.yml up -d
----

Now go to your web-browser and open `https://<domain>`. This page will display information about this machine.
Now you can stop this dummy server again:

[source,bash]
----
sudo docker-compose -f dummy-webserver-compose.yml down
----

Just to be safe you can check out the content of `acme.json` for your domain:

[source,bash]
----
sudo cat ./data/acme/acme.json
----

=== Mailserver

Next start the mailserver and create a dummy email (`test@<domain>`).
This is needed to generate a `DKIM`.
As this mailserver is not exposed to the internet and only used for sending mails, the dummy email should not be a security risk:

[source,bash]
----
sudo docker-compose up -d mailserver
cd ./scripts
. ../.env && docker exec -e HOST=${HOST} -it ecs_mailserver \
  /bin/bash -c 'echo "test@$HOST|$(doveadm pw -s SHA512-CRYPT -u test@$HOST -p password)" >> /tmp/docker-mailserver/postfix-accounts.cf'
./setup.sh config dkim
cd ..
----

=== ECS

Now comes the `ecs` itself. Just to be safe, we will restart everything:

[source,bash]
----
sudo docker-compose down
sudo docker-compose up -d
----

=== DKIM

Finally we need to set the `DKIM` record. Execute the following to get the `DKIM` record:

[source,bash]
----
. ./.env && sudo cat ./data/mailserver/config/opendkim/keys/${HOST}/mail.txt
----

== Backup (need to verify)

Backup is automatically started when doing:

[source,bash]
----
sudo docker-compose up -d
----

=== Manual backup

Trigger a backup manually:

[source,bash]
----
sudo docker exec ecs_backup /etc/periodic/daily/jobrunner
----

=== Restore backup

We will restore the backups to `./restore`:

[source,bash]
----
docker run --rm \
  -v $PWD/restore:/mnt/backup/src \
  -v $PWD/backup:/backup \
  -e TZ=Europe/Vienna -e OPTIONS=--no-encryption -e DST=file:///backup \
  ghcr.io/tecnativa/docker-duplicity-docker:2.2.0 restore
----

After that you can copy the `restore/storage-vault` to `data/ecs/storage-vault` and apply the `sql`:

[source,bash]
----
TODO
----

=== Stop backup

To stop the backup for some reason:

[source,bash]
----
sudo docker-compose stop backup
----

=== Start backup

To start it again:

[source,bash]
----
sudo docker-compose start backup
----

== Scripts

All the scripts are located in `./scripts`.

To create a admin user:

[source,bash]
----
./create-internal-user.sh email@example.com first_name last_name m|f
----

To create a certificate for a admin user:

[source,bash]
----
./create-client-certificate.sh email@example.com name_of_cert 365
----

== Migrations

=== ecs-deployment to ecs-deployment

Just copy the `.env` and the `./data` folder to the new machine where the `ecs-deployment` is located and start `docker-compose`.

=== ecs-appliance to ecs-deployment

Generate a `.env` and set the variables based on the `env.yml`. This would include:

* HOST
* ECS_COMMISSION_UUID
* ECS_SECRET_KEY
* ECS_REGISTRATION_SECRET
* ECS_PASSWORD_RESET_SECRET
* ECS_VAULT_ENCRYPT
* ECS_VAULT_SIGN

Copy the `/data/ecs-pgdump/ecs.pgdump.gz` from the old machine to the new one. This could be done like this:

[source,bash]
----
scp root@old.machine:/data/ecs-pgdump/ecs.pgdump.gz ./
----

Follow the link:#first_time_setup[First time setup] until you need to apply the migrations. Instead of applying the migration, apply the dump from the old machine:

[source,bash]
----
cat ecs.pgdump.gz | gzip -d | \
  sudo docker exec -e PGPASSWORD=ecs -e PGUSER=ecs -i ecs_database \
  bash -c "pg_restore -1 -O -F c -n public -d ecs"
----

Continue with the link:#first_time_setup[First time setup]

When you are done, all the directories should be now generated and we can migrate the `storage-vault`:

[source,bash]
----
rsync -r root@old.machine:/data/ecs-storage-vault/ ./data/ecs/storage-vault
----

The System is now migrated!

== TODO:

* Test `handy signatur`. The `pdf-as-web` was a little bit adjusted. It runs and can be called in the browser but just to be sure.
* A `backup-system` needs to be implemented.
